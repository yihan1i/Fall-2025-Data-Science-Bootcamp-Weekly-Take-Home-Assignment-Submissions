{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e50351-15c7-4379-9369-cd41cd7ac272",
   "metadata": {},
   "source": [
    "# (Homework) Week 6 - DataScience Bootcamp Fall 2025\n",
    "\n",
    "All solution cells are replaced with `# TODO` placeholders so you can fill them in.\n",
    "\n",
    "**Name: Yihan** \\\n",
    "**Email: yl13522@nyu.edu**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ae2a1-9b4d-4b8e-87a8-fd32d8c107c8",
   "metadata": {},
   "source": [
    "### Problem 1: Dataset Splitting\n",
    "\n",
    "1. You have recordings of 44 phones from 100 people; each person records ~200 phones/day for 5 days.\n",
    "   - Design a valid training/validation/test split strategy that ensures the model generalizes to **new speakers**.\n",
    "\n",
    "2. You now receive an additional dataset of 10,000 phone recordings from **Kilian**, a single speaker.\n",
    "   - You must train a model that performs well **specifically for Kilian**, while also maintaining generalization.\n",
    "\n",
    "*Describe your proposed split strategy and reasoning.* (Theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65cfdb6-aca2-4dd7-aaa4-70fa30af475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo 1. I would use the nearest neighbor approach, as \n",
    "# 2. In the case of optimizing the program for Killian's recordings, I would use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b7930-1fef-4fd2-ac71-1467e8b165e8",
   "metadata": {},
   "source": [
    "### Problem 2: K-Nearest Neighbors\n",
    "\n",
    "1. **1-NN Classification:** Given dataset:\n",
    "\n",
    "   Positive: (1,2), (1,4), (5,4)\n",
    "\n",
    "   Negative: (3,1), (3,2)\n",
    "\n",
    "   Plot the 1-NN decision boundary and classify new points visually.\n",
    "\n",
    "2. **Feature Scaling:** Consider dataset:\n",
    "\n",
    "   Positive: (100,2), (100,4), (500,4)\n",
    "\n",
    "   Negative: (300,1), (300,2)\n",
    "\n",
    "   What would the 1-NN classify point (500,1) as **before and after scaling** to [0,1] per feature?\n",
    "\n",
    "3. **Handling Missing Values:** How can you modify K-NN to handle missing features in a test point?\n",
    "\n",
    "4. **High-dimensional Data:** Why can K-NN still work well for images even with thousands of pixels?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadab25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f66d2-4e36-4e30-8ef5-72d9b7986ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo  1. \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "# Dataset\n",
    "positive = np.array([[1, 2], [1, 4], [5, 4]])\n",
    "negative = np.array([[3, 1], [3, 2]])\n",
    "\n",
    "# Combine all points for Voronoi diagram\n",
    "all_points = np.vstack([positive, negative])\n",
    "labels = ['Pos'] * len(positive) + ['Neg'] * len(negative)\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(positive[:, 0], positive[:, 1], c='blue', s=200, marker='o', \n",
    "           edgecolors='black', linewidth=2, label='Positive', zorder=3)\n",
    "ax.scatter(negative[:, 0], negative[:, 1], c='red', s=200, marker='s', \n",
    "           edgecolors='black', linewidth=2, label='Negative', zorder=3)\n",
    "\n",
    "# Annotate points\n",
    "for i, point in enumerate(positive):\n",
    "    ax.annotate(f'P{i+1}', (point[0], point[1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "for i, point in enumerate(negative):\n",
    "    ax.annotate(f'N{i+1}', (point[0], point[1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "# Create decision boundary using Voronoi diagram\n",
    "vor = Voronoi(all_points)\n",
    "\n",
    "# Plot Voronoi regions (simplified decision boundary)\n",
    "for simplex in vor.ridge_vertices:\n",
    "    simplex = np.asarray(simplex)\n",
    "    if np.all(simplex >= 0):\n",
    "        ax.plot(vor.vertices[simplex, 0], vor.vertices[simplex, 1], \n",
    "                'k-', linewidth=1.5, alpha=0.6)\n",
    "\n",
    "# Color regions based on nearest neighbor\n",
    "x_min, x_max = -0.5, 6.5\n",
    "y_min, y_max = 0, 5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Calculate 1-NN classification for each point in grid\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "predictions = []\n",
    "\n",
    "for point in grid_points:\n",
    "    distances = np.sqrt(np.sum((all_points - point)**2, axis=1))\n",
    "    nearest_idx = np.argmin(distances)\n",
    "    predictions.append(1 if nearest_idx < len(positive) else 0)\n",
    "\n",
    "predictions = np.array(predictions).reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions\n",
    "ax.contourf(xx, yy, predictions, alpha=0.2, levels=[0, 0.5, 1], \n",
    "            colors=['red', 'blue'])\n",
    "\n",
    "ax.set_xlabel('Feature 1', fontsize=12)\n",
    "ax.set_ylabel('Feature 2', fontsize=12)\n",
    "ax.set_title('1-NN Decision Boundary', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test some example points\n",
    "test_points = np.array([[2, 3], [4, 2], [2, 1]])\n",
    "print(\"\\nClassification of test points:\")\n",
    "for point in test_points:\n",
    "    distances = np.sqrt(np.sum((all_points - point)**2, axis=1))\n",
    "    nearest_idx = np.argmin(distances)\n",
    "    nearest_point = all_points[nearest_idx]\n",
    "    label = 'Positive' if nearest_idx < len(positive) else 'Negative'\n",
    "    print(f\"Point {point} -> Nearest: {nearest_point}, Distance: {distances[nearest_idx]:.2f}, Class: {label}\")\n",
    "#2.\n",
    "#3.\n",
    "# 4.K-NN still works well for images with thousands of pixels because the k value can be adjusted to the optmizaed value to be cable to correctly catagorize the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f766e-e313-4c28-a2af-b8a7985e3db7",
   "metadata": {},
   "source": [
    "### Problem 3: Part 1\n",
    "\n",
    "You are given a fully trained Perceptron model with weight vector **w**, along with training set **D_TR** and test set **D_TE**.\n",
    "\n",
    "1. Your co-worker suggests evaluating $h(x) = sign(w \\cdot x)$ for every $(x, y)$ in D_TR and D_TE. Does this help determine whether test error is higher than training error?\n",
    "2. Why is there no need to compute training error explicitly for the Perceptron algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca95dc-c37e-4f56-ab0a-9913bde3079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e8682-2b9f-4b15-a38e-2d3ec75591dc",
   "metadata": {},
   "source": [
    "### Problem 3: Two-point 2D Dataset (Part 2)\n",
    "\n",
    "Run the Perceptron algorithm **by hand or in code** on the following data:\n",
    "\n",
    "1. Positive class: (10, -2)\n",
    "2. Negative class: (12, 2)\n",
    "\n",
    "Start with $w_0 = (0, 0)$ and a learning rate of 1.\n",
    "\n",
    "- Compute how many updates are required until convergence.\n",
    "- Write down the sequence of $w_i$ vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4597a-387e-4d5d-bbe3-f621afd13625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba29c20-59b0-456f-994e-05897175596e",
   "metadata": {},
   "source": [
    "### Problem 4: Reconstructing the Weight Vector\n",
    "\n",
    "Given the log of Perceptron updates:\n",
    "\n",
    "| x | y | count |\n",
    "|---|---|--------|\n",
    "| (0, 0, 0, 0, 4) | +1 | 2 |\n",
    "| (0, 0, 6, 5, 0) | +1 | 1 |\n",
    "| (3, 0, 0, 0, 0) | -1 | 1 |\n",
    "| (0, 9, 3, 6, 0) | -1 | 1 |\n",
    "| (0, 1, 0, 2, 5) | -1 | 1 |\n",
    "\n",
    "Assume learning rate = 1 and initial weight $w_0 = (0, 0, 0, 0, 0)$.\n",
    "\n",
    "Compute the final weight vector after all updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb261e-d6ba-4ecd-a4f4-e9b6f5104079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f23b69-9f59-46c6-8103-5783fadeb7c0",
   "metadata": {},
   "source": [
    "### Problem 5: Visualizing Perceptron Convergence\n",
    "\n",
    "Implement a Perceptron on a small 2D dataset with positive and negative examples.\n",
    "\n",
    "- Plot the data points.\n",
    "- After each update, visualize the decision boundary.\n",
    "- Show how it converges to a stable separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879a3a9-de75-40a0-a901-bd2009d2b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
